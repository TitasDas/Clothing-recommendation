{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1d17ae5",
   "metadata": {},
   "source": [
    "# SAR "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109a3df6",
   "metadata": {},
   "source": [
    "SAR is a fast, scalable, adaptive algorithm for personalized recommendations based on user transaction history. It is powered by understanding the similarity between items, and recommending similar items to those a user has an existing affinity for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8000f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/test/lib/python3.7/site-packages/papermill/iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  from pyarrow import HadoopFileSystem\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.7.10 | packaged by conda-forge | (default, Oct 13 2021, 20:45:05) \n",
      "[Clang 11.1.0 ]\n",
      "Pandas version: 1.1.5\n"
     ]
    }
   ],
   "source": [
    "# set the environment path to find Recommenders\n",
    "import sys\n",
    "\n",
    "import itertools\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import papermill as pm\n",
    "import datetime\n",
    "from functools import wraps\n",
    "\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.python_splitters import python_stratified_split, python_chrono_split\n",
    "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k, diversity, novelty, serendipity, distributional_coverage, catalog_coverage \n",
    "from recommenders.models.sar.sar_singlenode import SARSingleNode\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "422f1241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "\n",
    "# results table\n",
    "cols = [\"Data\", \"Algo\", \"K\", \"Train time (s)\",\"Predicting time (s)\", \"RMSE\", \"MAE\", \"R2\", \"Explained Variance\", \"Recommending time (s)\", \"MAP\", \"nDCG@k\", \"Precision@k\", \"Recall@k\",\"Diversity\",\"Novelty\",\"Distributional coverage\",\"Catalog coverage\"]\n",
    "df_results = pd.DataFrame(columns=cols)\n",
    "\n",
    "def generate_summary(data, algo, k, train_time, rating_time, rating_metrics, ranking_time, ranking_metrics, diversity_metrics):\n",
    "    summary = {\"Data\": data, \"Algo\": algo, \"K\": k, \"Train time (s)\": train_time, \"Predicting time (s)\": rating_time, \"Recommending time (s)\":ranking_time}\n",
    "    if rating_metrics is None:\n",
    "        rating_metrics = {\n",
    "            \"RMSE\": np.nan,\n",
    "            \"MAE\": np.nan,\n",
    "            \"R2\": np.nan,\n",
    "            \"Explained Variance\": np.nan,\n",
    "        }\n",
    "    if ranking_metrics is None:\n",
    "        ranking_metrics = {\n",
    "            \"MAP\": np.nan,\n",
    "            \"nDCG@k\": np.nan,\n",
    "            \"Precision@k\": np.nan,\n",
    "            \"Recall@k\": np.nan,\n",
    "        }\n",
    "    if diversity_metrics is None:\n",
    "        diversity_metrics = {\n",
    "        \"Diversity\": np.nan,\n",
    "        \"Novelty\": np.nan,\n",
    "        \"Distributional coverage\": np.nan,\n",
    "        \"Catalog coverage\": np.nan,\n",
    "    }\n",
    "    summary.update(diversity_metrics)\n",
    "    summary.update(rating_metrics)\n",
    "    summary.update(ranking_metrics)\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "def convert_timestamp(datetime):\n",
    "    date_string = str(datetime)\n",
    "    date = datetime.datetime.strptime(date_string, \"%m/%d/%Y\")\n",
    "    timestamp = datetime.datetime.timestamp(date)\n",
    "    return(timestamp)\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Convert the float precision to 32-bit in order to reduce memory consumption \n",
    "    df.loc[:, header[\"col_rating\"]] = df[header[\"col_rating\"]].astype(np.float32)\n",
    "\n",
    "    ## convert datetime64[ns] to pd.timestamp, then to datetime and finally to timestamp int in second\n",
    "    df[\"order_date\"] = df[\"order_date\"].apply(lambda x: int(pd.to_datetime(pd.Timestamp(x), unit='s').strftime('%s')))\n",
    "    \n",
    "    return df \n",
    "\n",
    "def timing(f):\n",
    "    @wraps(f)\n",
    "    def wrap(*args, **kw):\n",
    "        ts = time()\n",
    "        result = f(*args, **kw)\n",
    "        te = time()\n",
    "        arg = args[0] if len(args)>=1 else \"\" \n",
    "        print('func:%r  took: %2.4f sec' % \\\n",
    "          (f.__name__, te-ts))\n",
    "        return result\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c83dbb",
   "metadata": {},
   "source": [
    "# 0. Config params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30f919d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table results \n",
    "algo = \"sar\"\n",
    "ranking_metrics = None\n",
    "rating_metrics = None\n",
    "diversity_metrics = None\n",
    "train_time = np.nan\n",
    "rating_time = np.nan\n",
    "ranking_time = np.nan\n",
    "\n",
    "# column name \n",
    "header = {\n",
    "    \"col_user\": \"customer_id\",\n",
    "    \"col_item\": \"variant_id\",\n",
    "    \"col_rating\": \"quantity\",\n",
    "    \"col_timestamp\": \"order_date\",\n",
    "    \"col_prediction\": \"Prediction\",\n",
    "}\n",
    "\n",
    "# top k\n",
    "TOP_K = 10\n",
    "\n",
    "################ TO MODIFY ################\n",
    "\n",
    "# date size with 3 choices : \"100k\",\"1M\" and \"all\"\n",
    "data_size = \"100k\"\n",
    "# load splitted data \n",
    "load_splitted_data = True \n",
    "\n",
    "################ TO MODIFY ################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea88923a",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab9bd96",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efb1146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### TO MODIFY ###########\n",
    "def load_data(data_size):\n",
    "    path = \"\"\n",
    "    if data_size==\"100k\":\n",
    "        path = '../../data/transaction_100k_df.pkl'\n",
    "    elif data_size==\"1M\":\n",
    "        path = '../../data/transaction_1M_df.pkl'\n",
    "    elif data_size==\"all\":\n",
    "        path = '../../data/transaction_all_df.pkl'\n",
    "    \n",
    "    if path != \"\":\n",
    "        return pd.read_pickle(path)\n",
    "    else :\n",
    "        print(\"Please choose between 100k, 1M and all\")\n",
    "########### TO MODIFY ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3164d43-2fb2-485e-9d1d-3ae7c007a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 ways to load the data\n",
    "if not load_splitted_data : \n",
    "    # data not splitted \n",
    "    data = load_data(data_size)\n",
    "else :\n",
    "    # or  use stored splitted data to make it faster\n",
    "    train = pd.read_pickle(f\"../../data/train_{data_size}_df.pkl\")\n",
    "    test = pd.read_pickle(f\"../../data/test_{data_size}_df.pkl\")\n",
    "    train.shape[0], test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374a068d",
   "metadata": {},
   "source": [
    "## 1.2 Split the data ( skip if load_splitted_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22cbf7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrono split but it is really slow ( +1h to split 8M data ) \n",
    "if not load_splitted_data :\n",
    "    train, test = python_chrono_split(data,\n",
    "                                      ratio=0.75,\n",
    "                                      col_user=header[\"col_user\"],\n",
    "                                      col_item=header[\"col_item\"],\n",
    "                                      col_timestamp = header[\"col_timestamp\"]\n",
    "                                     )\n",
    "    train.to_pickle(f\"../../data/train_{data_size}_df.pkl\")\n",
    "    test.to_pickle(f\"../../data/test_{data_size}_df.pkl\")\n",
    "    train.shape[0], test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8908e461-481d-4e43-a95a-c6b0468bde11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train:\n",
      "Total Ratings: 74944\n",
      "Unique Users: 720\n",
      "Unique Items: 5348\n",
      "\n",
      "Test:\n",
      "Total Ratings: 24983\n",
      "Unique Users: 720\n",
      "Unique Items: 4090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Train:\n",
    "Total Ratings: {train_total}\n",
    "Unique Users: {train_users}\n",
    "Unique Items: {train_items}\n",
    "\n",
    "Test:\n",
    "Total Ratings: {test_total}\n",
    "Unique Users: {test_users}\n",
    "Unique Items: {test_items}\n",
    "\"\"\".format(\n",
    "    train_total=len(train),\n",
    "    train_users=len(train[header[\"col_user\"]].unique()),\n",
    "    train_items=len(train[header[\"col_item\"]].unique()),\n",
    "    test_total=len(test),\n",
    "    test_users=len(test[header[\"col_user\"]].unique()),\n",
    "    test_items=len(test[header[\"col_item\"]].unique()),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de30533a-f1cf-4347-964e-e7196c420646",
   "metadata": {},
   "source": [
    "## 1.3 Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4afa324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preprocess_data(train)\n",
    "test = preprocess_data(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cbd0de",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f273c488-2815-4d40-9d7d-457419f6b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model param\n",
    "# similarity function with 3 choices : \"jaccard\", \"lift\" and \"counts\"\n",
    "similarity_type=\"jaccard\"\n",
    "# time decay T\n",
    "time_decay_coefficient=15\n",
    "# timedecay activated or not \n",
    "timedecay_formula=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eab88e",
   "metadata": {},
   "source": [
    "## 2.1 Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c61193d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set log level to INFO\n",
    "logging.basicConfig(level=logging.DEBUG, \n",
    "                    format='%(asctime)s %(levelname)-8s %(message)s')\n",
    "\n",
    "model = SARSingleNode(\n",
    "    similarity_type=similarity_type, \n",
    "    time_decay_coefficient=time_decay_coefficient, \n",
    "    timedecay_formula=timedecay_formula, \n",
    "    **header,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed3453d",
   "metadata": {},
   "source": [
    "## 2.2 Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9d0129c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-25 15:34:55,507 INFO     Collecting user affinity matrix\n",
      "2021-10-25 15:34:55,514 INFO     Calculating time-decayed affinities\n",
      "2021-10-25 15:34:55,580 INFO     Creating index columns\n",
      "2021-10-25 15:34:55,648 INFO     Building user affinity sparse matrix\n",
      "2021-10-25 15:34:55,654 INFO     Calculating item co-occurrence\n",
      "2021-10-25 15:34:56,101 INFO     Calculating item similarity\n",
      "2021-10-25 15:34:56,102 INFO     Using jaccard based similarity\n",
      "2021-10-25 15:34:57,865 INFO     Done training\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(train)\n",
    "train_time = time.time()-start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4979cac2",
   "metadata": {},
   "source": [
    "## 2.3  recommend k items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e45b913e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-25 15:34:58,000 INFO     Calculating recommendation scores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-25 15:34:58,384 INFO     Removing seen items\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>variant_id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>US051502171641244282</td>\n",
       "      <td>438626</td>\n",
       "      <td>3.784013e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>US051502171641244282</td>\n",
       "      <td>432868</td>\n",
       "      <td>3.570986e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>US051502171641244282</td>\n",
       "      <td>434314</td>\n",
       "      <td>3.520696e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>US051502171641244282</td>\n",
       "      <td>429811</td>\n",
       "      <td>3.495227e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7170</th>\n",
       "      <td>US621111115825890</td>\n",
       "      <td>436289</td>\n",
       "      <td>3.232004e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5895</th>\n",
       "      <td>US621111114281349</td>\n",
       "      <td>425669</td>\n",
       "      <td>2.064447e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5896</th>\n",
       "      <td>US621111114281349</td>\n",
       "      <td>426232</td>\n",
       "      <td>1.990251e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5897</th>\n",
       "      <td>US621111114281349</td>\n",
       "      <td>422911</td>\n",
       "      <td>1.965823e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5898</th>\n",
       "      <td>US621111114281349</td>\n",
       "      <td>427391</td>\n",
       "      <td>1.956576e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5899</th>\n",
       "      <td>US621111114281349</td>\n",
       "      <td>418394</td>\n",
       "      <td>1.923996e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               customer_id variant_id    Prediction\n",
       "1690  US051502171641244282     438626  3.784013e-01\n",
       "1691  US051502171641244282     432868  3.570986e-01\n",
       "1692  US051502171641244282     434314  3.520696e-01\n",
       "1693  US051502171641244282     429811  3.495227e-01\n",
       "7170     US621111115825890     436289  3.232004e-01\n",
       "...                    ...        ...           ...\n",
       "5895     US621111114281349     425669  2.064447e-08\n",
       "5896     US621111114281349     426232  1.990251e-08\n",
       "5897     US621111114281349     422911  1.965823e-08\n",
       "5898     US621111114281349     427391  1.956576e-08\n",
       "5899     US621111114281349     418394  1.923996e-08\n",
       "\n",
       "[7200 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top k items to recommend\n",
    "start = time.time()\n",
    "n = 100000\n",
    "tests = []\n",
    "for i in range(0,len(test),n):\n",
    "    print(i)\n",
    "    if i+n<len(test):\n",
    "        test_sample = test[i:i+n]\n",
    "    else:\n",
    "        test_sample = test[i:]\n",
    "    top_k = model.recommend_k_items(test_sample, top_k = TOP_K, remove_seen=True)\n",
    "    tests.append(top_k)\n",
    "ranking_time = time.time()-start\n",
    "top_k = pd.concat(tests)\n",
    "top_k = top_k.sort_values(by=[header[\"col_prediction\"]], ascending=False)\n",
    "top_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc39cbe",
   "metadata": {},
   "source": [
    "# 3. Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6387de22",
   "metadata": {},
   "source": [
    "## 3.1 Ranking metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efeef4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\n",
      "Top K:\t\t 10\n",
      "MAP:\t\t 0.015832\n",
      "NDCG:\t\t 0.120409\n",
      "Precision@K:\t 0.111250\n",
      "Recall@K:\t 0.031310\n"
     ]
    }
   ],
   "source": [
    "args = [test, top_k]\n",
    "\n",
    "kwargs = dict(col_user = header[\"col_user\"],\n",
    "              col_item = header[\"col_item\"],\n",
    "              col_rating= header[\"col_rating\"],\n",
    "              col_prediction= header[\"col_prediction\"],\n",
    "              relevancy_method='top_k', \n",
    "              k=TOP_K)\n",
    "\n",
    "eval_map = map_at_k(*args, **kwargs)\n",
    "eval_ndcg = ndcg_at_k(*args, **kwargs)\n",
    "eval_precision = precision_at_k(*args, **kwargs)\n",
    "eval_recall = recall_at_k(*args, **kwargs)\n",
    "\n",
    "ranking_metrics = {\n",
    "    \"MAP\": eval_map,\n",
    "    \"nDCG@k\": eval_ndcg,\n",
    "    \"Precision@k\": eval_precision,\n",
    "    \"Recall@k\": eval_recall,\n",
    "}\n",
    "\n",
    "print(f\"Model:\",\n",
    "      f\"Top K:\\t\\t {TOP_K}\",\n",
    "      f\"MAP:\\t\\t {eval_map:f}\",\n",
    "      f\"NDCG:\\t\\t {eval_ndcg:f}\",\n",
    "      f\"Precision@K:\\t {eval_precision:f}\",\n",
    "      f\"Recall@K:\\t {eval_recall:f}\",sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbefd20b",
   "metadata": {},
   "source": [
    "## 3.2 Diversity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52db16e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\n",
      "Diversity :\t 0.7602995530883522\n",
      "Novelty:\t 11.058183\n",
      "Coverage:\t 8.978610\n"
     ]
    }
   ],
   "source": [
    "args = [train, top_k]\n",
    "\n",
    "kwargs = dict(col_user = header[\"col_user\"],\n",
    "              col_item = header[\"col_item\"],\n",
    "             )\n",
    "\n",
    "eval_diversity = diversity(*args, **kwargs)\n",
    "eval_novelty = novelty(*args, **kwargs)\n",
    "eval_distributional_coverage = distributional_coverage(*args, **kwargs)\n",
    "eval_catalog_coverage = catalog_coverage(*args,**kwargs)\n",
    "\n",
    "diversity_metrics = {\n",
    "    \"Diversity\": eval_diversity,\n",
    "    \"Novelty\": eval_novelty,\n",
    "    \"Distributional coverage\": eval_distributional_coverage,\n",
    "    \"Catalog coverage\": eval_catalog_coverage,\n",
    "}\n",
    "        \n",
    "print(f\"Model:\",\n",
    "      f\"Diversity :\\t {eval_diversity}\",\n",
    "      f\"Novelty:\\t {eval_novelty:f}\",\n",
    "      f\"Coverage:\\t {eval_distributional_coverage:f}\", sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c35d9b",
   "metadata": {},
   "source": [
    "# 4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fae88313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Algo</th>\n",
       "      <th>K</th>\n",
       "      <th>Train time (s)</th>\n",
       "      <th>Predicting time (s)</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Explained Variance</th>\n",
       "      <th>Recommending time (s)</th>\n",
       "      <th>MAP</th>\n",
       "      <th>nDCG@k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>Diversity</th>\n",
       "      <th>Novelty</th>\n",
       "      <th>Distributional coverage</th>\n",
       "      <th>Catalog coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all</td>\n",
       "      <td>sar</td>\n",
       "      <td>10</td>\n",
       "      <td>18.093610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.601460</td>\n",
       "      <td>0.100136</td>\n",
       "      <td>0.138245</td>\n",
       "      <td>0.034234</td>\n",
       "      <td>0.21693</td>\n",
       "      <td>0.957637</td>\n",
       "      <td>11.336318</td>\n",
       "      <td>11.040913</td>\n",
       "      <td>0.957958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100k</td>\n",
       "      <td>sar</td>\n",
       "      <td>10</td>\n",
       "      <td>1.867308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.340116</td>\n",
       "      <td>0.015832</td>\n",
       "      <td>0.120409</td>\n",
       "      <td>0.111250</td>\n",
       "      <td>0.03131</td>\n",
       "      <td>0.760300</td>\n",
       "      <td>11.058183</td>\n",
       "      <td>8.978610</td>\n",
       "      <td>0.274308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Algo   K  Train time (s)  Predicting time (s)  RMSE  MAE  R2  \\\n",
       "1   all  sar  10       18.093610                  NaN   NaN  NaN NaN   \n",
       "2  100k  sar  10        1.867308                  NaN   NaN  NaN NaN   \n",
       "\n",
       "   Explained Variance  Recommending time (s)       MAP    nDCG@k  Precision@k  \\\n",
       "1                 NaN             211.601460  0.100136  0.138245     0.034234   \n",
       "2                 NaN               1.340116  0.015832  0.120409     0.111250   \n",
       "\n",
       "   Recall@k  Diversity    Novelty  Distributional coverage  Catalog coverage  \n",
       "1   0.21693   0.957637  11.336318                11.040913          0.957958  \n",
       "2   0.03131   0.760300  11.058183                 8.978610          0.274308  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = generate_summary(data_size,\n",
    "                           algo,\n",
    "                           TOP_K,\n",
    "                           train_time, \n",
    "                           rating_time,\n",
    "                           rating_metrics,\n",
    "                           ranking_time,\n",
    "                           ranking_metrics,\n",
    "                           diversity_metrics)\n",
    "df_results.loc[df_results.shape[0] + 1] = summary\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a2d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
