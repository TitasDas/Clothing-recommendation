{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1d17ae5",
   "metadata": {},
   "source": [
    "# Popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8000f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.13 | packaged by conda-forge | (default, Sep 23 2021, 07:55:15) \n",
      "[GCC Clang 11.1.0]\n",
      "Pandas version: 1.1.5\n"
     ]
    }
   ],
   "source": [
    "# set the environment path to find Recommenders\n",
    "import sys\n",
    "\n",
    "import itertools\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import papermill as pm\n",
    "import datetime\n",
    "from functools import wraps\n",
    "\n",
    "from recommenders.datasets.python_splitters import python_stratified_split, python_chrono_split\n",
    "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k, diversity, novelty, serendipity, distributional_coverage, catalog_coverage \n",
    "from recommenders.utils.timer import Timer\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "422f1241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "\n",
    "# results table\n",
    "cols = [\"Data\", \"Algo\", \"K\", \"Train time (s)\",\"Predicting time (s)\", \"RMSE\", \"MAE\", \"R2\", \"Explained Variance\", \"Recommending time (s)\", \"MAP\", \"nDCG@k\", \"Precision@k\", \"Recall@k\",\"Diversity\",\"Novelty\",\"Distributional coverage\",\"Catalog coverage\"]\n",
    "df_results = pd.DataFrame(columns=cols)\n",
    "\n",
    "def generate_summary(data, algo, k, train_time, rating_time, rating_metrics, ranking_time, ranking_metrics, diversity_metrics):\n",
    "    summary = {\"Data\": data, \"Algo\": algo, \"K\": k, \"Train time (s)\": train_time, \"Predicting time (s)\": rating_time, \"Recommending time (s)\":ranking_time}\n",
    "    if rating_metrics is None:\n",
    "        rating_metrics = {\n",
    "            \"RMSE\": np.nan,\n",
    "            \"MAE\": np.nan,\n",
    "            \"R2\": np.nan,\n",
    "            \"Explained Variance\": np.nan,\n",
    "        }\n",
    "    if ranking_metrics is None:\n",
    "        ranking_metrics = {\n",
    "            \"MAP\": np.nan,\n",
    "            \"nDCG@k\": np.nan,\n",
    "            \"Precision@k\": np.nan,\n",
    "            \"Recall@k\": np.nan,\n",
    "        }\n",
    "    if diversity_metrics is None:\n",
    "        diversity_metrics = {\n",
    "        \"Diversity\": np.nan,\n",
    "        \"Novelty\": np.nan,\n",
    "        \"Distributional coverage\": np.nan,\n",
    "        \"Catalog coverage\": np.nan,\n",
    "    }\n",
    "    summary.update(diversity_metrics)\n",
    "    summary.update(rating_metrics)\n",
    "    summary.update(ranking_metrics)\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "def convert_timestamp(datetime):\n",
    "    date_string = str(datetime)\n",
    "    date = datetime.datetime.strptime(date_string, \"%m/%d/%Y\")\n",
    "    timestamp = datetime.datetime.timestamp(date)\n",
    "    return(timestamp)\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Convert the float precision to 32-bit in order to reduce memory consumption \n",
    "    df.loc[:, header[\"col_rating\"]] = df[header[\"col_rating\"]].astype(np.float32)\n",
    "    df = df[[header[\"col_user\"],header[\"col_item\"],header[\"col_rating\"]]]\n",
    "    return df \n",
    "\n",
    "def timing(f):\n",
    "    @wraps(f)\n",
    "    def wrap(*args, **kw):\n",
    "        ts = time()\n",
    "        result = f(*args, **kw)\n",
    "        te = time()\n",
    "        arg = args[0] if len(args)>=1 else \"\" \n",
    "        print('func:%r  took: %2.4f sec' % \\\n",
    "          (f.__name__, te-ts))\n",
    "        return result\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c83dbb",
   "metadata": {},
   "source": [
    "# 0. Config params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30f919d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table results \n",
    "algo = \"popular\"\n",
    "ranking_metrics = None\n",
    "rating_metrics = None\n",
    "diversity_metrics = None\n",
    "train_time = np.nan\n",
    "rating_time = np.nan\n",
    "ranking_time = np.nan\n",
    "\n",
    "# column name \n",
    "header = {\n",
    "    \"col_user\": \"customer_id\",\n",
    "    \"col_item\": \"variant_id\",\n",
    "    \"col_rating\": \"quantity\",\n",
    "    \"col_timestamp\": \"order_date\",\n",
    "    \"col_prediction\": \"prediction\",\n",
    "}\n",
    "\n",
    "# top k\n",
    "TOP_K = 10\n",
    "\n",
    "################ TO MODIFY ################\n",
    "\n",
    "# date size with 3 choices : \"100k\",\"1M\" and \"all\"\n",
    "data_size = \"all\"\n",
    "# load splitted data \n",
    "load_splitted_data = True \n",
    "\n",
    "################ TO MODIFY ################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea88923a",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab9bd96",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efb1146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### TO MODIFY ###########\n",
    "def load_data(data_size):\n",
    "    path = \"\"\n",
    "    if data_size==\"100k\":\n",
    "        path = '../../data/transaction_100k_df.pkl'\n",
    "    elif data_size==\"1M\":\n",
    "        path = '../../data/transaction_1M_df.pkl'\n",
    "    elif data_size==\"all\":\n",
    "        path = '../../data/transaction_all_df.pkl'\n",
    "    \n",
    "    if path != \"\":\n",
    "        return pd.read_pickle(path)\n",
    "    else :\n",
    "        print(\"Please choose between 100k, 1M and all\")\n",
    "########### TO MODIFY ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3164d43-2fb2-485e-9d1d-3ae7c007a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 ways to load the data\n",
    "if not load_splitted_data : \n",
    "    # data not splitted \n",
    "    data = load_data(data_size)\n",
    "else :\n",
    "    # or  use stored splitted data to make it faster\n",
    "    train = pd.read_pickle(f\"../../data/train_{data_size}_df.pkl\")\n",
    "    test = pd.read_pickle(f\"../../data/test_{data_size}_df.pkl\")\n",
    "    train.shape[0], test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374a068d",
   "metadata": {},
   "source": [
    "## 1.2 Split the data ( skip if load_splitted_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22cbf7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrono split but it is really slow ( +1h to split 8M data ) \n",
    "if not load_splitted_data :\n",
    "    train, test = python_chrono_split(data,\n",
    "                                      ratio=0.75,\n",
    "                                      col_user=header[\"col_user\"],\n",
    "                                      col_item=header[\"col_item\"],\n",
    "                                      col_timestamp = header[\"col_timestamp\"]\n",
    "                                     )\n",
    "    train.to_pickle(f\"../../data/train_{data_size}_df.pkl\")\n",
    "    test.to_pickle(f\"../../data/test_{data_size}_df.pkl\")\n",
    "    train.shape[0], test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8908e461-481d-4e43-a95a-c6b0468bde11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train:\n",
      "Total Ratings: 6041296\n",
      "Unique Users: 1497612\n",
      "Unique Items: 7659\n",
      "\n",
      "Test:\n",
      "Total Ratings: 1799883\n",
      "Unique Users: 869943\n",
      "Unique Items: 7022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Train:\n",
    "Total Ratings: {train_total}\n",
    "Unique Users: {train_users}\n",
    "Unique Items: {train_items}\n",
    "\n",
    "Test:\n",
    "Total Ratings: {test_total}\n",
    "Unique Users: {test_users}\n",
    "Unique Items: {test_items}\n",
    "\"\"\".format(\n",
    "    train_total=len(train),\n",
    "    train_users=len(train[header[\"col_user\"]].unique()),\n",
    "    train_items=len(train[header[\"col_item\"]].unique()),\n",
    "    test_total=len(test),\n",
    "    test_users=len(test[header[\"col_user\"]].unique()),\n",
    "    test_items=len(test[header[\"col_item\"]].unique()),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de30533a-f1cf-4347-964e-e7196c420646",
   "metadata": {},
   "source": [
    "## 1.3 Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4afa324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preprocess_data(train)\n",
    "test = preprocess_data(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cbd0de",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4979cac2",
   "metadata": {},
   "source": [
    "## 2.3  recommend k items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e45b913e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138a864959a94d19a92485d6643d67c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1497612 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with Timer() as ranking_time:\n",
    "    # get the 100 most popular items \n",
    "    top = train.groupby(header[\"col_item\"]).agg({header[\"col_rating\"]:\"sum\"}).sort_values(by=[header[\"col_rating\"]],ascending=False).reset_index()\n",
    "    top = top.head(100)[header[\"col_item\"]].tolist()\n",
    "\n",
    "    users = []\n",
    "    items = []\n",
    "    list_users = list(train[header[\"col_user\"]].unique())\n",
    "\n",
    "    for user in tqdm(list_users):\n",
    "        users += [user]*100\n",
    "        items += top\n",
    "\n",
    "    top_all = pd.DataFrame({header[\"col_user\"]:users,header[\"col_item\"]:items})\n",
    "\n",
    "    # remove seen items and \n",
    "    top_k = pd.merge(train, top_all, on = [header[\"col_user\"],header[\"col_item\"]],how=\"outer\",indicator=True)\n",
    "    top_k = top_k[top_k['_merge']=='right_only']\n",
    "\n",
    "    # select the 10 most popular items\n",
    "    top_k = top_k.groupby(header[\"col_user\"]).head(TOP_K)\n",
    "    top_k[header[\"col_prediction\"]] = top_k.groupby(header[\"col_user\"], sort=False).cumcount() + 1\n",
    "    top_k = top_k.drop(header[\"col_rating\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc39cbe",
   "metadata": {},
   "source": [
    "# 3. Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6387de22",
   "metadata": {},
   "source": [
    "## 3.1 Ranking metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "efeef4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\n",
      "Top K:\t\t 10\n",
      "MAP:\t\t 0.009730\n",
      "NDCG:\t\t 0.020413\n",
      "Precision@K:\t 0.007956\n",
      "Recall@K:\t 0.047232\n"
     ]
    }
   ],
   "source": [
    "args = [test, top_k]\n",
    "\n",
    "kwargs = dict(col_user = header[\"col_user\"],\n",
    "              col_item = header[\"col_item\"],\n",
    "              col_rating= header[\"col_rating\"],\n",
    "              col_prediction= header[\"col_prediction\"],\n",
    "              relevancy_method='top_k', \n",
    "              k=TOP_K)\n",
    "\n",
    "eval_map = map_at_k(*args, **kwargs)\n",
    "eval_ndcg = ndcg_at_k(*args, **kwargs)\n",
    "eval_precision = precision_at_k(*args, **kwargs)\n",
    "eval_recall = recall_at_k(*args, **kwargs)\n",
    "\n",
    "ranking_metrics = {\n",
    "    \"MAP\": eval_map,\n",
    "    \"nDCG@k\": eval_ndcg,\n",
    "    \"Precision@k\": eval_precision,\n",
    "    \"Recall@k\": eval_recall,\n",
    "}\n",
    "\n",
    "print(f\"Model:\",\n",
    "      f\"Top K:\\t\\t {TOP_K}\",\n",
    "      f\"MAP:\\t\\t {eval_map:f}\",\n",
    "      f\"NDCG:\\t\\t {eval_ndcg:f}\",\n",
    "      f\"Precision@K:\\t {eval_precision:f}\",\n",
    "      f\"Recall@K:\\t {eval_recall:f}\",sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbefd20b",
   "metadata": {},
   "source": [
    "## 3.2 Diversity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52db16e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/rec/lib/python3.6/site-packages/recommenders/evaluation/python_evaluation.py:760: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reco_df[col_relevance] = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\n",
      "Diversity :\t 0.9687655323330641\n",
      "Novelty:\t 7.961962\n",
      "Distributional Coverage:\t 3.409857\n",
      "Catalog Coverage:\t 0.002481\n"
     ]
    }
   ],
   "source": [
    "args = [train, top_k]\n",
    "\n",
    "kwargs = dict(col_user = header[\"col_user\"],\n",
    "              col_item = header[\"col_item\"],\n",
    "             )\n",
    "\n",
    "eval_diversity = diversity(*args, **kwargs)\n",
    "eval_novelty = novelty(*args, **kwargs)\n",
    "eval_distributional_coverage = distributional_coverage(*args, **kwargs)\n",
    "eval_catalog_coverage = catalog_coverage(*args,**kwargs)\n",
    "\n",
    "diversity_metrics = {\n",
    "    \"Diversity\": eval_diversity,\n",
    "    \"Novelty\": eval_novelty,\n",
    "    \"Distributional coverage\": eval_distributional_coverage,\n",
    "    \"Catalog coverage\": eval_catalog_coverage,\n",
    "}\n",
    "        \n",
    "print(f\"Model:\",\n",
    "      f\"Diversity :\\t {eval_diversity}\",\n",
    "      f\"Novelty:\\t {eval_novelty:f}\",\n",
    "      f\"Distributional Coverage:\\t {eval_distributional_coverage:f}\",\n",
    "      f\"Catalog Coverage:\\t {eval_catalog_coverage:f}\", sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c35d9b",
   "metadata": {},
   "source": [
    "# 4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fae88313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Algo</th>\n",
       "      <th>K</th>\n",
       "      <th>Train time (s)</th>\n",
       "      <th>Predicting time (s)</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Explained Variance</th>\n",
       "      <th>Recommending time (s)</th>\n",
       "      <th>MAP</th>\n",
       "      <th>nDCG@k</th>\n",
       "      <th>Precision@k</th>\n",
       "      <th>Recall@k</th>\n",
       "      <th>Diversity</th>\n",
       "      <th>Novelty</th>\n",
       "      <th>Distributional coverage</th>\n",
       "      <th>Catalog coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100k</td>\n",
       "      <td>popular</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>0.045793</td>\n",
       "      <td>0.049583</td>\n",
       "      <td>0.013647</td>\n",
       "      <td>0.725257</td>\n",
       "      <td>8.942318</td>\n",
       "      <td>3.980020</td>\n",
       "      <td>0.004488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1M</td>\n",
       "      <td>popular</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.3132</td>\n",
       "      <td>0.003371</td>\n",
       "      <td>0.016208</td>\n",
       "      <td>0.019308</td>\n",
       "      <td>0.018529</td>\n",
       "      <td>0.877848</td>\n",
       "      <td>8.577696</td>\n",
       "      <td>3.619350</td>\n",
       "      <td>0.003416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all</td>\n",
       "      <td>popular</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>322.5469</td>\n",
       "      <td>0.009730</td>\n",
       "      <td>0.020413</td>\n",
       "      <td>0.007956</td>\n",
       "      <td>0.047232</td>\n",
       "      <td>0.968766</td>\n",
       "      <td>7.961962</td>\n",
       "      <td>3.409857</td>\n",
       "      <td>0.002481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data     Algo   K  Train time (s)  Predicting time (s)  RMSE  MAE  R2  \\\n",
       "1  100k  popular  10             NaN                  NaN   NaN  NaN NaN   \n",
       "2    1M  popular  10             NaN                  NaN   NaN  NaN NaN   \n",
       "3   all  popular  10             NaN                  NaN   NaN  NaN NaN   \n",
       "\n",
       "   Explained Variance Recommending time (s)       MAP    nDCG@k  Precision@k  \\\n",
       "1                 NaN                0.2397  0.004115  0.045793     0.049583   \n",
       "2                 NaN                2.3132  0.003371  0.016208     0.019308   \n",
       "3                 NaN              322.5469  0.009730  0.020413     0.007956   \n",
       "\n",
       "   Recall@k  Diversity   Novelty  Distributional coverage  Catalog coverage  \n",
       "1  0.013647   0.725257  8.942318                 3.980020          0.004488  \n",
       "2  0.018529   0.877848  8.577696                 3.619350          0.003416  \n",
       "3  0.047232   0.968766  7.961962                 3.409857          0.002481  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = generate_summary(data_size,\n",
    "                           algo,\n",
    "                           TOP_K,\n",
    "                           train_time, \n",
    "                           rating_time,\n",
    "                           rating_metrics,\n",
    "                           ranking_time,\n",
    "                           ranking_metrics,\n",
    "                           diversity_metrics)\n",
    "df_results.loc[df_results.shape[0] + 1] = summary\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
