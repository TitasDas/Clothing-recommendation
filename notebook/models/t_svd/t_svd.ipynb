{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cfd9c94-9f84-4de6-97d6-e4f6b86ea27d",
   "metadata": {},
   "source": [
    "# T_SVD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98ef2c9-000c-44c0-b3c2-1ac4fc57f777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.13 | packaged by conda-forge | (default, Sep 23 2021, 07:55:15) \n",
      "[GCC Clang 11.1.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import wraps\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.python_splitters import python_random_split, python_chrono_split\n",
    "from recommenders.evaluation.python_evaluation import (rmse, mae, rsquared, exp_var,\n",
    "                                                       map_at_k, ndcg_at_k, precision_at_k, recall_at_k,\n",
    "                                                       diversity, novelty, distributional_coverage, catalog_coverage )\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a22545a2-5044-4c8d-9ed8-8f66ef987e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "\n",
    "# results table\n",
    "cols = [\"Data\", \"Algo\", \"K\", \"Train time (s)\",\"Predicting time (s)\", \"RMSE\", \"MAE\", \"R2\", \"Explained Variance\", \"Recommending time (s)\", \"MAP\", \"nDCG@k\", \"Precision@k\", \"Recall@k\",\"Diversity\",\"Novelty\",\"Distributional coverage\",\"Catalog coverage\"]\n",
    "df_results = pd.DataFrame(columns=cols)\n",
    "\n",
    "def generate_summary(data, algo, k, train_time, rating_time, rating_metrics, ranking_time, ranking_metrics, diversity_metrics):\n",
    "    summary = {\"Data\": data, \"Algo\": algo, \"K\": k, \"Train time (s)\": train_time, \"Predicting time (s)\": rating_time, \"Recommending time (s)\":ranking_time}\n",
    "    if rating_metrics is None:\n",
    "        rating_metrics = {\n",
    "            \"RMSE\": np.nan,\n",
    "            \"MAE\": np.nan,\n",
    "            \"R2\": np.nan,\n",
    "            \"Explained Variance\": np.nan,\n",
    "        }\n",
    "    if ranking_metrics is None:\n",
    "        ranking_metrics = {\n",
    "            \"MAP\": np.nan,\n",
    "            \"nDCG@k\": np.nan,\n",
    "            \"Precision@k\": np.nan,\n",
    "            \"Recall@k\": np.nan,\n",
    "        }\n",
    "    if diversity_metrics is None:\n",
    "        diversity_metrics = {\n",
    "        \"Diversity\": np.nan,\n",
    "        \"Novelty\": np.nan,\n",
    "        \"Distributional coverage\": np.nan,\n",
    "        \"Catalog coverage\": np.nan,\n",
    "    }\n",
    "    summary.update(diversity_metrics)\n",
    "    summary.update(rating_metrics)\n",
    "    summary.update(ranking_metrics)\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "def convert_timestamp(datetime):\n",
    "    date_string = str(datetime)\n",
    "    date = datetime.datetime.strptime(date_string, \"%m/%d/%Y\")\n",
    "    timestamp = datetime.datetime.timestamp(date)\n",
    "    return(timestamp)\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Convert the float precision to 32-bit in order to reduce memory consumption \n",
    "    df.loc[:, header[\"col_rating\"]] = df[header[\"col_rating\"]].astype(np.float32)\n",
    "    df = df[[header[\"col_user\"],header[\"col_item\"],header[\"col_rating\"]]]\n",
    "    return df \n",
    "\n",
    "def timing(f):\n",
    "    @wraps(f)\n",
    "    def wrap(*args, **kw):\n",
    "        ts = time()\n",
    "        result = f(*args, **kw)\n",
    "        te = time()\n",
    "        arg = args[0] if len(args)>=1 else \"\" \n",
    "        print('func:%r  took: %2.4f sec' % \\\n",
    "          (f.__name__, te-ts))\n",
    "        return result\n",
    "    return wrap\n",
    "\n",
    "def _list_similar_products(product_id, utility_matrix, correlation_matrix,k,all_items_bought=set()):\n",
    "    product_names = list(utility_matrix.index)\n",
    "    product_id_index = product_names.index(product_id)\n",
    "    correlation_product_id = correlation_matrix[product_id_index]\n",
    "    correlation_product_id_indexed = [ (product_names[i],j) for i,j in enumerate(correlation_product_id) if product_names[i] not in all_items_bought ]\n",
    "    correlation_product_id_indexed.sort(key=lambda x : x[1],reverse = True)\n",
    "    recommendations = correlation_product_id_indexed[:k]\n",
    "    return recommendations\n",
    "\n",
    "def get_top_k_items_t_svd(train,utility_matrix,correlation_matrix,col_user,col_item,col_rating,col_prediction,k,remove_seen=True):\n",
    "    top_k = pd.DataFrame({col_user:[],col_item:[],col_prediction:[]})\n",
    "    users = []\n",
    "    items = []\n",
    "    scores = []\n",
    "    # get the top products (based on the number of items bought) for each customer \n",
    "    idx = train.groupby([col_user])[col_rating].transform(max) == train[col_rating]\n",
    "    top_products_per_customer = train[idx].drop_duplicates(subset=col_user, keep=\"last\")\n",
    "    for i in tqdm(range(len(top_products_per_customer)), desc = 'Customer'):\n",
    "        customer = top_products_per_customer[col_user].iloc[i]\n",
    "        top_product = top_products_per_customer[col_item].iloc[i]\n",
    "        # get all the products bought by the customer \n",
    "        if remove_seen:\n",
    "            all_items_bought = set(train[train[col_user]==customer][col_item])\n",
    "        else:\n",
    "            all_items_bought = set()\n",
    "        list_similar_items_score = _list_similar_products(top_product, utility_matrix, correlation_matrix,k,all_items_bought)\n",
    "        for j in range(len(list_similar_items_score)):\n",
    "            item, score = list_similar_items_score[j]\n",
    "            users.append(customer)\n",
    "            items.append(item)\n",
    "            scores.append(score)\n",
    "    top_k[col_user]=users\n",
    "    top_k[col_item]=items\n",
    "    top_k[col_prediction]=scores\n",
    "    return(top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39af46c0-e0ce-4888-8729-2bd8501b62bf",
   "metadata": {},
   "source": [
    "# 0. Config params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b08ab576-c92b-4eb5-b610-0ec7c4812e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table results \n",
    "algo = \"t_svd\"\n",
    "ranking_metrics = None\n",
    "rating_metrics = None\n",
    "diversity_metrics = None\n",
    "train_time = np.nan\n",
    "rating_time = np.nan\n",
    "ranking_time = np.nan\n",
    "\n",
    "# column name \n",
    "header = {\n",
    "    \"col_user\": \"customer_id\",\n",
    "    \"col_item\": \"variant_id\",\n",
    "    \"col_rating\": \"quantity\",\n",
    "    \"col_timestamp\": \"order_date\",\n",
    "    \"col_prediction\": \"prediction\",\n",
    "}\n",
    "\n",
    "# top k\n",
    "TOP_K = 10\n",
    "\n",
    "################ TO MODIFY ################\n",
    "\n",
    "# date size with 3 choices : \"100k\",\"1M\" and \"all\"\n",
    "data_size = \"all\"\n",
    "# load splitted data \n",
    "load_splitted_data = True \n",
    "\n",
    "################ TO MODIFY ################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a940089b-6655-4937-bffd-1bfbcd007796",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a7a91d-7ded-49a0-a8c2-3899926dcef4",
   "metadata": {},
   "source": [
    "# 1.1 Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5921f03-ae02-47a7-a7c8-e8be710836ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### TO MODIFY ###########\n",
    "def load_data(data_size):\n",
    "    path = \"\"\n",
    "    if data_size==\"100k\":\n",
    "        path = '../../data/transaction_100k_df.pkl'\n",
    "    elif data_size==\"1M\":\n",
    "        path = '../../data/transaction_1M_df.pkl'\n",
    "    elif data_size==\"all\":\n",
    "        path = '../../data/transaction_all_df.pkl'\n",
    "    \n",
    "    if path != \"\":\n",
    "        return pd.read_pickle(path)\n",
    "    else :\n",
    "        print(\"Please choose between 100k, 1M and all\")\n",
    "########### TO MODIFY ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b507ac49-3587-4636-88d6-bd790c2a0432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 ways to load the data\n",
    "if not load_splitted_data : \n",
    "    # data not splitted \n",
    "    data = load_data(data_size)\n",
    "else :\n",
    "    # or  use stored splitted data to make it faster\n",
    "    train = pd.read_pickle(f\"../../data/train_{data_size}_df.pkl\")\n",
    "    test = pd.read_pickle(f\"../../data/test_{data_size}_df.pkl\")\n",
    "    train.shape[0], test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915661e3-737f-4821-9f8e-447e5cb80deb",
   "metadata": {},
   "source": [
    "## 1.2 Split the data ( skip if load_splitted_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "310b5a58-f1ed-4f43-8e23-f948b9cf8797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrono split but it is really slow ( +1h to split 8M data ) \n",
    "if not load_splitted_data :\n",
    "    train, test = python_chrono_split(data,\n",
    "                                      ratio=0.75,\n",
    "                                      col_user=header[\"col_user\"],\n",
    "                                      col_item=header[\"col_item\"],\n",
    "                                      col_timestamp = header[\"col_timestamp\"]\n",
    "                                     )\n",
    "    train.to_pickle(f\"../../data/train_{data_size}_df.pkl\")\n",
    "    test.to_pickle(f\"../../data/test_{data_size}_df.pkl\")\n",
    "    train.shape[0], test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91adcf7a-483d-46f4-9011-3834ddc6fb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train:\n",
      "Total Ratings: 6041296\n",
      "Unique Users: 1497612\n",
      "Unique Items: 7659\n",
      "\n",
      "Test:\n",
      "Total Ratings: 1799883\n",
      "Unique Users: 869943\n",
      "Unique Items: 7022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Train:\n",
    "Total Ratings: {train_total}\n",
    "Unique Users: {train_users}\n",
    "Unique Items: {train_items}\n",
    "\n",
    "Test:\n",
    "Total Ratings: {test_total}\n",
    "Unique Users: {test_users}\n",
    "Unique Items: {test_items}\n",
    "\"\"\".format(\n",
    "    train_total=len(train),\n",
    "    train_users=len(train[header[\"col_user\"]].unique()),\n",
    "    train_items=len(train[header[\"col_item\"]].unique()),\n",
    "    test_total=len(test),\n",
    "    test_users=len(test[header[\"col_user\"]].unique()),\n",
    "    test_items=len(test[header[\"col_item\"]].unique()),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09087006-f2bf-4b52-8c13-a5305dd01a96",
   "metadata": {},
   "source": [
    "## 1.3 Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b871460c-ecc2-458b-a537-6514fd204c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preprocess_data(train)\n",
    "test = preprocess_data(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab54151-edfc-4046-9289-7a52bc33c328",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c06e12-3c62-4aa8-aadb-4e5ac13f80ac",
   "metadata": {},
   "source": [
    "## 2.1 Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ca4c82-7e97-4f35-b169-9f3fea25a0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c79ff15e68c4fb991a99f104a1f3d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-47fb17c6ab67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"col_user\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     )\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mratings_utility_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings_utility_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteractions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#ratings_utility_matrix = train.pivot_table(values=header[\"col_rating\"], index= header[\"col_user\"],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/rec/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   7749\u001b[0m             \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7750\u001b[0m             \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7751\u001b[0;31m             \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7752\u001b[0m         )\n\u001b[1;32m   7753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/rec/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/rec/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             new_data = concatenate_block_managers(\n\u001b[0;32m--> 503\u001b[0;31m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             )\n\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/rec/lib/python3.6/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             b = make_block(\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0m_concatenate_join_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             )\n",
      "\u001b[0;32m/opt/anaconda3/envs/rec/lib/python3.6/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36m_concatenate_join_units\u001b[0;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mconcat_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mconcat_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconcat_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcat_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/rec/lib/python3.6/site-packages/pandas/core/dtypes/concat.py\u001b[0m in \u001b[0;36mconcat_compat\u001b[0;34m(to_concat, axis)\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0mto_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create pivot table from chunk in order to prevent int32 overflow ( pivot_table function do not work well )\n",
    "chunk_size = 5000\n",
    "chunks = [x for x in range(0, train.shape[0], chunk_size)]\n",
    "\n",
    "ratings_utility_matrix = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(0, len(chunks) - 1)):\n",
    "    chunk_df = train.iloc[ chunks[i]:chunks[i + 1] - 1]\n",
    "    interactions = (\n",
    "    chunk_df.groupby([header[\"col_user\"], header[\"col_item\"]])[header[\"col_rating\"]]\n",
    "    .sum()\n",
    "    .unstack()\n",
    "    .reset_index()\n",
    "    .fillna(0)\n",
    "    .set_index(header[\"col_user\"])\n",
    "    )\n",
    "    ratings_utility_matrix = ratings_utility_matrix.append(interactions, sort=False) \n",
    "    \n",
    "#ratings_utility_matrix = train.pivot_table(values=header[\"col_rating\"], index= header[\"col_user\"],\n",
    "#                                                         columns=header[\"col_item\"], fill_value=0)\n",
    "utility_matrix = ratings_utility_matrix.T\n",
    "t_svd = TruncatedSVD(n_components=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff3b8a7-821c-4ebd-82da-4f55110aa234",
   "metadata": {},
   "source": [
    "## 2.2 Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b09c927-ff01-461f-8c92-de4c159b4a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as train_time:\n",
    "    decomposed_matrix = t_svd.fit_transform(utility_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a9e8f7-865b-4c69-b3ef-67c9739fe07e",
   "metadata": {},
   "source": [
    "## 2.4  recommend k items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3036e206-d143-4ae3-8933-b309c6da76e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as ranking_time:\n",
    "    correlation_matrix = np.corrcoef(decomposed_matrix)\n",
    "    print(\"correlation matrix computed\")\n",
    "    top_k = get_top_k_items_t_svd(train,\n",
    "                                  utility_matrix,\n",
    "                                  correlation_matrix,\n",
    "                                  col_user=header[\"col_user\"],\n",
    "                                  col_item=header[\"col_item\"],\n",
    "                                  col_rating=header[\"col_rating\"],\n",
    "                                  col_prediction = header[\"col_prediction\"],\n",
    "                                  k=TOP_K,\n",
    "                                  remove_seen=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c823aa31-fb1a-4221-a93a-712856c4f439",
   "metadata": {},
   "source": [
    "# 3. Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ea896e-2479-494a-94c0-bcd0c4e7af4b",
   "metadata": {},
   "source": [
    "## 3.1 Ranking metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17868dea-408d-46ff-89ad-3c7fa3a1cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [test, top_k]\n",
    "\n",
    "kwargs = dict(col_user = header[\"col_user\"],\n",
    "              col_item = header[\"col_item\"],\n",
    "              col_rating = header[\"col_rating\"],\n",
    "              relevancy_method = 'top_k', \n",
    "              k = TOP_K)\n",
    "\n",
    "eval_map = map_at_k(*args, **kwargs)\n",
    "eval_ndcg = ndcg_at_k(*args, **kwargs)\n",
    "eval_precision = precision_at_k(*args, **kwargs)\n",
    "eval_recall = recall_at_k(*args, **kwargs)\n",
    "\n",
    "ranking_metrics = {\n",
    "    \"MAP\": eval_map,\n",
    "    \"nDCG@k\": eval_ndcg,\n",
    "    \"Precision@k\": eval_precision,\n",
    "    \"Recall@k\": eval_recall\n",
    "}\n",
    "\n",
    "print(f\"Model:\",\n",
    "      f\"Top K:\\t\\t {TOP_K}\",\n",
    "      f\"MAP:\\t\\t {eval_map:f}\",\n",
    "      f\"NDCG:\\t\\t {eval_ndcg:f}\",\n",
    "      f\"Precision@K:\\t {eval_precision:f}\",\n",
    "      f\"Recall@K:\\t {eval_recall:f}\",sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec48273-8945-4025-abb4-ec98552fdc8b",
   "metadata": {},
   "source": [
    "## 3.2 Diversity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b8ecff-3987-475e-8549-2dd964024b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [train, top_k]\n",
    "\n",
    "kwargs = dict(col_user = header[\"col_user\"],\n",
    "              col_item = header[\"col_item\"],\n",
    "             )\n",
    "\n",
    "eval_diversity = diversity(*args, **kwargs)\n",
    "eval_novelty = novelty(*args, **kwargs)\n",
    "eval_distributional_coverage = distributional_coverage(*args, **kwargs)\n",
    "eval_catalog_coverage = catalog_coverage(*args,**kwargs)\n",
    "\n",
    "diversity_metrics = {\n",
    "    \"Diversity\": eval_diversity,\n",
    "    \"Novelty\": eval_novelty,\n",
    "    \"Distributional coverage\": eval_distributional_coverage,\n",
    "    \"Catalog coverage\": eval_catalog_coverage,\n",
    "}\n",
    "        \n",
    "print(f\"Model:\",\n",
    "      f\"Diversity :\\t\\t\\t {eval_diversity}\",\n",
    "      f\"Novelty:\\t\\t\\t {eval_novelty:f}\",\n",
    "      f\"Catalog coverage:\\t\\t {eval_catalog_coverage:f}\",\n",
    "      f\"Distributional coverage:\\t {eval_distributional_coverage:f}\",sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cba30e9-0480-4c15-acba-07166547dbf4",
   "metadata": {},
   "source": [
    "# 4 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98069e4d-3011-449a-9fa7-ed2a6f0b4f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = generate_summary(data_size,\n",
    "                           algo,\n",
    "                           TOP_K,\n",
    "                           train_time, \n",
    "                           rating_time,\n",
    "                           rating_metrics,\n",
    "                           ranking_time,\n",
    "                           ranking_metrics,\n",
    "                           diversity_metrics)\n",
    "df_results.loc[df_results.shape[0] + 1] = summary\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2980bf65-6b9c-4568-bfbc-9c6e325850a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
